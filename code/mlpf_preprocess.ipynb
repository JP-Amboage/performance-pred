{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "132"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"../data/mlpf/delphes_trainings.pkl\", \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "len(data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"bin_size\",\"dropout\",\"lr\",\"n_glayers_id\",\"n_glayers_reg\"]\n",
    "columns.extend([\"loss_\"+str(i) for i in range(100)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bin_size</th>\n",
       "      <th>dropout</th>\n",
       "      <th>lr</th>\n",
       "      <th>n_glayers_id</th>\n",
       "      <th>n_glayers_reg</th>\n",
       "      <th>loss_0</th>\n",
       "      <th>loss_1</th>\n",
       "      <th>loss_2</th>\n",
       "      <th>loss_3</th>\n",
       "      <th>loss_4</th>\n",
       "      <th>...</th>\n",
       "      <th>loss_90</th>\n",
       "      <th>loss_91</th>\n",
       "      <th>loss_92</th>\n",
       "      <th>loss_93</th>\n",
       "      <th>loss_94</th>\n",
       "      <th>loss_95</th>\n",
       "      <th>loss_96</th>\n",
       "      <th>loss_97</th>\n",
       "      <th>loss_98</th>\n",
       "      <th>loss_99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16.0</td>\n",
       "      <td>0.006203</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>533.897949</td>\n",
       "      <td>533.939148</td>\n",
       "      <td>533.939026</td>\n",
       "      <td>533.938904</td>\n",
       "      <td>533.938843</td>\n",
       "      <td>...</td>\n",
       "      <td>533.938782</td>\n",
       "      <td>533.938782</td>\n",
       "      <td>533.938782</td>\n",
       "      <td>533.938782</td>\n",
       "      <td>533.938782</td>\n",
       "      <td>533.938782</td>\n",
       "      <td>533.938782</td>\n",
       "      <td>533.938782</td>\n",
       "      <td>533.938782</td>\n",
       "      <td>533.938782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64.0</td>\n",
       "      <td>0.181440</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>633.963013</td>\n",
       "      <td>566.545837</td>\n",
       "      <td>546.444580</td>\n",
       "      <td>535.711731</td>\n",
       "      <td>528.940125</td>\n",
       "      <td>...</td>\n",
       "      <td>520.286743</td>\n",
       "      <td>520.165466</td>\n",
       "      <td>520.169861</td>\n",
       "      <td>520.292908</td>\n",
       "      <td>520.464355</td>\n",
       "      <td>520.651123</td>\n",
       "      <td>520.850769</td>\n",
       "      <td>521.073181</td>\n",
       "      <td>521.296692</td>\n",
       "      <td>521.533203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16.0</td>\n",
       "      <td>0.257000</td>\n",
       "      <td>0.000340</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>492.217072</td>\n",
       "      <td>471.338928</td>\n",
       "      <td>472.664246</td>\n",
       "      <td>473.120575</td>\n",
       "      <td>472.047882</td>\n",
       "      <td>...</td>\n",
       "      <td>474.869324</td>\n",
       "      <td>474.922974</td>\n",
       "      <td>474.983826</td>\n",
       "      <td>474.955231</td>\n",
       "      <td>475.082001</td>\n",
       "      <td>475.255493</td>\n",
       "      <td>492.020630</td>\n",
       "      <td>471.808075</td>\n",
       "      <td>472.234894</td>\n",
       "      <td>472.483948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>0.206670</td>\n",
       "      <td>0.000589</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>493.532410</td>\n",
       "      <td>478.761566</td>\n",
       "      <td>478.476288</td>\n",
       "      <td>477.996429</td>\n",
       "      <td>477.813751</td>\n",
       "      <td>...</td>\n",
       "      <td>480.048004</td>\n",
       "      <td>480.064087</td>\n",
       "      <td>480.065765</td>\n",
       "      <td>480.062531</td>\n",
       "      <td>480.060608</td>\n",
       "      <td>480.058289</td>\n",
       "      <td>480.061127</td>\n",
       "      <td>480.086395</td>\n",
       "      <td>480.069122</td>\n",
       "      <td>480.078705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32.0</td>\n",
       "      <td>0.110180</td>\n",
       "      <td>0.000364</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>477.201294</td>\n",
       "      <td>456.798492</td>\n",
       "      <td>452.933197</td>\n",
       "      <td>451.200287</td>\n",
       "      <td>450.279114</td>\n",
       "      <td>...</td>\n",
       "      <td>443.141449</td>\n",
       "      <td>443.343689</td>\n",
       "      <td>443.721680</td>\n",
       "      <td>443.360077</td>\n",
       "      <td>443.229492</td>\n",
       "      <td>443.268372</td>\n",
       "      <td>443.288086</td>\n",
       "      <td>443.213593</td>\n",
       "      <td>443.121033</td>\n",
       "      <td>443.183472</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 105 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   bin_size   dropout        lr  n_glayers_id  n_glayers_reg      loss_0  \\\n",
       "0      16.0  0.006203  0.000141           4.0            1.0  533.897949   \n",
       "1      64.0  0.181440  0.000003           4.0            1.0  633.963013   \n",
       "2      16.0  0.257000  0.000340           1.0            2.0  492.217072   \n",
       "3      16.0  0.206670  0.000589           2.0            0.0  493.532410   \n",
       "4      32.0  0.110180  0.000364           2.0            3.0  477.201294   \n",
       "\n",
       "       loss_1      loss_2      loss_3      loss_4  ...     loss_90  \\\n",
       "0  533.939148  533.939026  533.938904  533.938843  ...  533.938782   \n",
       "1  566.545837  546.444580  535.711731  528.940125  ...  520.286743   \n",
       "2  471.338928  472.664246  473.120575  472.047882  ...  474.869324   \n",
       "3  478.761566  478.476288  477.996429  477.813751  ...  480.048004   \n",
       "4  456.798492  452.933197  451.200287  450.279114  ...  443.141449   \n",
       "\n",
       "      loss_91     loss_92     loss_93     loss_94     loss_95     loss_96  \\\n",
       "0  533.938782  533.938782  533.938782  533.938782  533.938782  533.938782   \n",
       "1  520.165466  520.169861  520.292908  520.464355  520.651123  520.850769   \n",
       "2  474.922974  474.983826  474.955231  475.082001  475.255493  492.020630   \n",
       "3  480.064087  480.065765  480.062531  480.060608  480.058289  480.061127   \n",
       "4  443.343689  443.721680  443.360077  443.229492  443.268372  443.288086   \n",
       "\n",
       "      loss_97     loss_98     loss_99  \n",
       "0  533.938782  533.938782  533.938782  \n",
       "1  521.073181  521.296692  521.533203  \n",
       "2  471.808075  472.234894  472.483948  \n",
       "3  480.086395  480.069122  480.078705  \n",
       "4  443.213593  443.121033  443.183472  \n",
       "\n",
       "[5 rows x 105 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=columns)\n",
    "for k in data.keys():\n",
    "    if data[k].shape[0] >= 100:\n",
    "        row = []\n",
    "        hps = k.split(',')[:-1]\n",
    "        for hp in hps:\n",
    "            row.append(float(hp.split('=')[1]))\n",
    "        for i in range(100):\n",
    "            row.append(float(data[k][\"loss\"][i]))\n",
    "        if len(row)==105:\n",
    "            df.loc[len(df.index)] = row\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(103, 105)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.to_csv(\"../data/mlpf/delphes_trainings_processed.csv\", encoding='utf-8', index=False)\n",
    "df.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('py39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1ac4248432e308955067782465497de26ed69bab2d310610bc1af3ad0fd9ab68"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
