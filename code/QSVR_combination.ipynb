{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine multiple QSVR trained with small data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from qa_summer.QSVR import QSVR\n",
    "from dimod import ExactSolver\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from utils import nb_utils\n",
    "from joblib import dump, load\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import datetime\n",
    "from random import randint, random\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVR\n",
    "import neal #import to use simulated annealing sampler\n",
    "from dwave.system import LazyFixedEmbeddingComposite, DWaveSampler #import to select specific sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = ''\n",
    "save = False\n",
    "num_splits = 1\n",
    "train_size = 80 # divisible by 20\n",
    "#date = datetime.datetime.now().strftime(\"_%Y_%m_%d-%I:%M:%S.%f_%p\")\n",
    "#experiment_name = experiment_name + date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load and scale data\n",
    "# load data\n",
    "df_info = nb_utils.get_df_info('mlpf')\n",
    "df = pd.read_csv(df_info['df_path'])\n",
    "df = df.drop(df[df.loss_99 == df.loss_99.max()].index)\n",
    "\n",
    "# Select features\n",
    "curve = nb_utils.get_curve(df_info=df_info, known_curve=0.25, df=df)\n",
    "X = curve[:,[i for i in range(0,curve.shape[1],2)]]\n",
    "\n",
    "# Prediction target\n",
    "y = nb_utils.get_target(df_info,df)\n",
    "\n",
    "# Scale data\n",
    "x_scaler = QuantileTransformer(n_quantiles=50,random_state=0)\n",
    "X = x_scaler.fit_transform(X)\n",
    "y_scaler =  QuantileTransformer(n_quantiles=50,random_state=0)\n",
    "y = y_scaler.fit_transform(y.reshape(-1, 1)).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the QUBO Q matrix of size (120, 120)\n",
      "Extracting nodes and couplers from Q\n",
      "The problem has 120 nodes and 7140 couplers\n",
      "Running with 120 nodes and 7140 couplers\n",
      "no field of name chain_break_fraction\n",
      "->trying with: result = rfn.merge_arrays((unique_samples, unique_records[\"energy\"], unique_counts))\n",
      "Creating the QUBO Q matrix of size (120, 120)\n",
      "Extracting nodes and couplers from Q\n",
      "The problem has 120 nodes and 7140 couplers\n",
      "Running with 120 nodes and 7140 couplers\n",
      "no field of name chain_break_fraction\n",
      "->trying with: result = rfn.merge_arrays((unique_samples, unique_records[\"energy\"], unique_counts))\n",
      "Creating the QUBO Q matrix of size (120, 120)\n",
      "Extracting nodes and couplers from Q\n",
      "The problem has 120 nodes and 7140 couplers\n",
      "Running with 120 nodes and 7140 couplers\n",
      "no field of name chain_break_fraction\n",
      "->trying with: result = rfn.merge_arrays((unique_samples, unique_records[\"energy\"], unique_counts))\n",
      "Creating the QUBO Q matrix of size (120, 120)\n",
      "Extracting nodes and couplers from Q\n",
      "The problem has 120 nodes and 7140 couplers\n",
      "Running with 120 nodes and 7140 couplers\n",
      "no field of name chain_break_fraction\n",
      "->trying with: result = rfn.merge_arrays((unique_samples, unique_records[\"energy\"], unique_counts))\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "WARNING: THIS CELL SENDS PROBLEMS TO D-WAVE MULTIPLE TIMES\n",
    "REMEMBRER D-WAVE AVALIABLE TIME IS LIMITED\n",
    "'''\n",
    "rs = randint(0, 2**30)\n",
    "for i in range(num_splits):\n",
    "    # train test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=rs+i)\n",
    "    X_train, y_train = X_train[:train_size], y_train[:train_size]\n",
    "\n",
    "    # split the training set in subsets of 20 elements an use each one to train a different\n",
    "    qsvr_models = []\n",
    "    for j in range(int(train_size/20)):\n",
    "        X_train_j, y_train_j = X_train[20*j:20*(j+1)], y_train[20*j:20*(j+1)]\n",
    "        model = QSVR.QSVR() # instantiate\n",
    "        #RUN ON D-WAVE\n",
    "        #set sampler\n",
    "        #sampler = LazyFixedEmbeddingComposite(DWaveSampler(region='na-west-1', solver='Advantage_system6.1'))\n",
    "        sampler = neal.SimulatedAnnealingSampler()\n",
    "        model.fit(X_train_j, y_train_j,\n",
    "            K = 3, B = 0.5,\n",
    "            epsilon = 0.02, k0 = 0.005,\n",
    "            xi=0.01, n_samples = 20,\n",
    "            #num_reads = 5000,\n",
    "            num_reads=1000,\n",
    "            random_seed=rs+i+j,\n",
    "            n_samples_for_gamma_and_C_optimizations=0,\n",
    "            gamma=0.1, C=67.61,\n",
    "            use_custom_chainstrength=True,\n",
    "            chain_mult=10,\n",
    "            #anneal_time=40,\n",
    "            sampler=sampler\n",
    "        )\n",
    "        if save: nb_utils.save_qsvr(model, 'qsvr_attrs_'+experiment_name+'_rs'+str(rs)+'_i'+str(i)+'_j'+str(j)) # save QSVR for further predictions\n",
    "        qsvr_models.append(nb_utils.qsvr_to_pred_dict(model))\n",
    "    \n",
    "    # combine trained models to do predictions\n",
    "    X_train_reshaped = qsvr_models[0]['X_train_reshaped']\n",
    "    Y_train = qsvr_models[0]['Y_train']\n",
    "    all_alphas = qsvr_models[0]['all_alphas']\n",
    "    for j in range(1,int(train_size/20)):\n",
    "        X_train_reshaped.extend(qsvr_models[j]['X_train_reshaped'])\n",
    "        Y_train = np.concatenate((Y_train, qsvr_models[j]['Y_train']))\n",
    "        all_alphas = np.concatenate((all_alphas,qsvr_models[j]['all_alphas']),axis=2)\n",
    "   \n",
    "    combined_model_dict = {}\n",
    "    combined_model_dict['X_train_reshaped'] = X_train_reshaped\n",
    "    combined_model_dict['Y_train'] = Y_train\n",
    "    combined_model_dict['all_alphas'] = all_alphas\n",
    "    combined_model_dict['B'] = qsvr_models[0]['B']\n",
    "    combined_model_dict['K'] = qsvr_models[0]['K']\n",
    "    combined_model_dict['epsilon'] = qsvr_models[0]['epsilon']\n",
    "    combined_model_dict['best_gamma'] = qsvr_models[0]['best_gamma']\n",
    "    combined_model_dict['best_C'] = qsvr_models[0]['best_C']\n",
    "    combined_model_dict['change_to_logarithmic'] = qsvr_models[0]['change_to_logarithmic']\n",
    "\n",
    "    pred_model = QSVR.QSVR() \n",
    "    # set the QSVR attributes needed for predictions\n",
    "    for attr in combined_model_dict.keys():\n",
    "        setattr(pred_model, attr, combined_model_dict[attr])\n",
    "    \n",
    "    y_pred = pred_model.predict(X_test)\n",
    "\n",
    "    # make use of the prediction\n",
    "    r2 = []\n",
    "    for i in range(y_pred.shape[0]):\n",
    "        r2.append(r2_score(y_pred[i],y_test))\n",
    "    r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.42369208044289974,\n",
       " 0.4202292296147857,\n",
       " 0.42368798705127675,\n",
       " 0.41736372154928336,\n",
       " 0.4202537480435057,\n",
       " 0.4245824882086835,\n",
       " 0.43084923841744227]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 148)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 20 is out of bounds for axis 0 with size 20",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/jp/CERN/repo/code/QSVR_combination.ipynb Celda 7\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jp/CERN/repo/code/QSVR_combination.ipynb#X10sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m         \u001b[39msetattr\u001b[39m(pred_model, attr, model_dict[attr])\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jp/CERN/repo/code/QSVR_combination.ipynb#X10sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     \u001b[39mprint\u001b[39m(y_pred\u001b[39m.\u001b[39mshape)    \n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/jp/CERN/repo/code/QSVR_combination.ipynb#X10sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     pred_model\u001b[39m.\u001b[39;49mpredict(X_test)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jp/CERN/repo/code/QSVR_combination.ipynb#X10sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     y_pred \u001b[39m=\u001b[39m y_pred \u001b[39m+\u001b[39m pred_model\u001b[39m.\u001b[39mpredict(X_test)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jp/CERN/repo/code/QSVR_combination.ipynb#X10sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m y_pred \u001b[39m=\u001b[39m y_pred \u001b[39m/\u001b[39m \u001b[39mfloat\u001b[39m(total)\n",
      "File \u001b[0;32m~/CERN/repo/code/qa_summer/QSVR/QSVR.py:431\u001b[0m, in \u001b[0;36mQSVR.predict\u001b[0;34m(self, X_values)\u001b[0m\n\u001b[1;32m    429\u001b[0m Y_scores \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mndarray(shape\u001b[39m=\u001b[39m(\u001b[39m7\u001b[39m, X_values\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m])) \u001b[39m#edited by juan, original: Y_scores = np.ndarray(shape=(6, X_values.shape[0]))\u001b[39;00m\n\u001b[1;32m    430\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(Y_scores\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]):\n\u001b[0;32m--> 431\u001b[0m     temp_output \u001b[39m=\u001b[39m utility\u001b[39m.\u001b[39;49mpredict(\n\u001b[1;32m    432\u001b[0m         X_test \u001b[39m=\u001b[39;49m X_values_reshaped, \n\u001b[1;32m    433\u001b[0m         X_train \u001b[39m=\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mX_train_reshaped, \n\u001b[1;32m    434\u001b[0m         Y_train \u001b[39m=\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mY_train,\n\u001b[1;32m    435\u001b[0m         alphas \u001b[39m=\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mall_alphas[i, \u001b[39m0\u001b[39;49m, :],\n\u001b[1;32m    436\u001b[0m         alphas_2 \u001b[39m=\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mall_alphas[i, \u001b[39m1\u001b[39;49m, :],\n\u001b[1;32m    437\u001b[0m         B \u001b[39m=\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mB,\n\u001b[1;32m    438\u001b[0m         K \u001b[39m=\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mK,\n\u001b[1;32m    439\u001b[0m         epsilon \u001b[39m=\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mepsilon,\n\u001b[1;32m    440\u001b[0m         gamma \u001b[39m=\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbest_gamma,\n\u001b[1;32m    441\u001b[0m         C \u001b[39m=\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbest_C\n\u001b[1;32m    442\u001b[0m         )\n\u001b[1;32m    443\u001b[0m     Y_scores[i, :] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mreshape(temp_output,(temp_output\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m],))\n\u001b[1;32m    445\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchange_to_logarithmic:\n",
      "File \u001b[0;32m~/CERN/repo/code/qa_summer/QSVR/utility.py:101\u001b[0m, in \u001b[0;36mpredict\u001b[0;34m(X_test, X_train, Y_train, alphas, alphas_2, B, K, epsilon, gamma, C)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(X_test, X_train, Y_train, alphas, alphas_2, B, K, epsilon, gamma, C):\n\u001b[1;32m     99\u001b[0m     b \u001b[39m=\u001b[39m eval_offset_avg(alphas, alphas_2, X_train, Y_train, epsilon, gamma, C) \u001b[39m#requires the reshaped version of X_train \u001b[39;00m\n\u001b[0;32m--> 101\u001b[0m     scoretest \u001b[39m=\u001b[39m eval_regressor(X_test, alphas, alphas_2, X_train, gamma,  b) \u001b[39m#requires the reshaped version of X_train and X_test\u001b[39;00m\n\u001b[1;32m    103\u001b[0m     \u001b[39mreturn\u001b[39;00m scoretest\n",
      "File \u001b[0;32m~/CERN/repo/code/qa_summer/QSVR/utility.py:75\u001b[0m, in \u001b[0;36meval_regressor\u001b[0;34m(x, alphas, alphas_2, data, gamma, b)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(data)):\n\u001b[1;32m     74\u001b[0m     k\u001b[39m=\u001b[39mkernel(x[i],data[j],gamma)\n\u001b[0;32m---> 75\u001b[0m     temp\u001b[39m+\u001b[39m\u001b[39m=\u001b[39malphas_d[j]\u001b[39m*\u001b[39mkernel(x[i],data[j],gamma)\n\u001b[1;32m     76\u001b[0m temp\u001b[39m+\u001b[39m\u001b[39m=\u001b[39mb\n\u001b[1;32m     77\u001b[0m res\u001b[39m.\u001b[39mappend(temp)\n",
      "\u001b[0;31mIndexError\u001b[0m: index 20 is out of bounds for axis 0 with size 20"
     ]
    }
   ],
   "source": [
    "total = len(qsvr_models)\n",
    "y_pred = np.zeros((7,y_test.shape[0]))\n",
    "for model_dict in qsvr_models:\n",
    "    pred_model = QSVR.QSVR() \n",
    "    # set the QSVR attributes needed for predictions\n",
    "    for attr in model_dict.keys():\n",
    "        setattr(pred_model, attr, model_dict[attr])\n",
    "    \n",
    "    y_pred = pred_model.predict(X_test)\n",
    "    print(y_pred.shape)    \n",
    "    pred_model.predict(X_test)\n",
    "    y_pred = y_pred + pred_model.predict(X_test)\n",
    "\n",
    "y_pred = y_pred / float(total)\n",
    "\n",
    "r2_ = []\n",
    "for i in range(y_pred.shape[0]):\n",
    "    r2_.append(r2_score(y_pred[i],y_test))\n",
    "r2_\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('py39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1ac4248432e308955067782465497de26ed69bab2d310610bc1af3ad0fd9ab68"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
