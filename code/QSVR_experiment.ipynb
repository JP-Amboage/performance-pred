{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run QSVR experiments with multiple splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from qa_summer.QSVR import QSVR\n",
    "from dimod import ExactSolver\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from utils import nb_utils\n",
    "from joblib import dump, load\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import datetime\n",
    "from random import randint, random\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVR\n",
    "import neal #import to use simulated annealing sampler\n",
    "from dwave.system import LazyFixedEmbeddingComposite, DWaveSampler #import to select specific sampler\n",
    "from dwave.system import VirtualGraphComposite\n",
    "from scipy.stats import loguniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_svr_hps = False\n",
    "experiment_name = ''\n",
    "save = True\n",
    "#date = datetime.datetime.now().strftime(\"_%Y_%m_%d-%I:%M:%S.%f_%p\")\n",
    "#experiment_name = experiment_name + date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run experiments with fixed epsilon, C and gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exiting cell as search_svr_hps is set to True\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "WARNING: THIS CELL SENDS PROBLEMS TO D-WAVE MULTIPLE TIMES\n",
    "REMEMBRER D-WAVE AVALIABLE TIME IS LIMITED\n",
    "'''\n",
    "if search_svr_hps: #ONLY RUNS FOR FIXED SVR PARAMS: epsilon, C and gamma\n",
    "\tnb_utils.exit_cell('Exiting cell as search_svr_hps is set to True')\n",
    "\n",
    "# load data\n",
    "df_info = nb_utils.get_df_info('mlpf')\n",
    "df = pd.read_csv(df_info['df_path'])\n",
    "df = df.drop(df[df.loss_99 == df.loss_99.max()].index)\n",
    "\n",
    "# Select features\n",
    "curve = nb_utils.get_curve(df_info=df_info, known_curve=0.25, df=df)\n",
    "X = curve[:,[i for i in range(0,curve.shape[1],2)]]\n",
    "\n",
    "# Prediction target\n",
    "y = nb_utils.get_target(df_info,df)\n",
    "\n",
    "# Scale data\n",
    "x_scaler = QuantileTransformer(n_quantiles=50,random_state=0)\n",
    "X = x_scaler.fit_transform(X)\n",
    "y_scaler =  QuantileTransformer(n_quantiles=50,random_state=0)\n",
    "y = y_scaler.fit_transform(y.reshape(-1, 1)).ravel()\n",
    "\n",
    "rs = randint(0, 2**30)\n",
    "num_runs = 10\n",
    "r2 = np.zeros((num_runs, 7))\n",
    "qsvr_model = QSVR.QSVR() # instantiate outside to reuse embedding and afford time\n",
    "for i in range(num_runs):\n",
    "\t# train test split\n",
    "\tX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=rs+i)\n",
    "\tX_train = X_train[:79,:]\n",
    "\ty_train = y_train[:79]\n",
    "\t\n",
    "\t# QSVR code\n",
    "\t#qsvr_model = QSVR.QSVR() # instantiate moved outside the loop\n",
    "\t#RUN ON D-WAVE\n",
    "\t#set sampler\n",
    "\t#sampler = LazyFixedEmbeddingComposite(DWaveSampler(region='na-west-1', solver='Advantage_system6.1'))\n",
    "\t#sampler = neal.SimulatedAnnealingSampler()\n",
    "\t#sampler = VirtualGraphComposite(DWaveSampler()) \n",
    "\tqsvr_model.fit(X_train, y_train,\n",
    "\t\t\tK = 3, B = 0.5,\n",
    "\t\t\tepsilon = 0.02, k0 = 0.005,\n",
    "\t\t\txi=0.01, n_samples = 20,\n",
    "\t\t\t#num_reads = 5000,\n",
    "\t\t\tnum_reads=1000,\n",
    "\t\t\trandom_seed=rs+i,\n",
    "\t\t\tn_samples_for_gamma_and_C_optimizations=40,\n",
    "\t\t\tgamma=0.1, C=67.61,\n",
    "\t\t\tuse_custom_chainstrength=True,\n",
    "\t\t\tchain_mult=10,\n",
    "\t\t\t#sampler=sampler,\n",
    "\t\t\tresult_percentage_used = 0.004\n",
    "\t\t)\n",
    "\t\n",
    "\tif save: nb_utils.save_qsvr(qsvr_model, 'qsvr_attrs_'+experiment_name+'_rs'+str(rs)+'_i'+str(i)) # save QSVR for further predictions\n",
    "\t\n",
    "\t# evaluate QSVR\n",
    "\ty_pred = qsvr_model.predict(X_test)\n",
    "\tfor j in range(7):\n",
    "\t\tr2[i,j] = r2_score(y_pred[j],y_test)\n",
    "\tprint(f'Finished run {i} with r2 = {r2[i,:]} with mean = {r2[i,:].mean()}')\n",
    "\n",
    "results = {\n",
    "\t'scores norm' : r2[:,0],\n",
    "\t'scores softmax' : r2[:,1],\n",
    "\t'scores lc norm' : r2[:,2],\n",
    "\t'scores lc softmax' : r2[:,3],\n",
    "\t'best set of alphas' : r2[:,4],\n",
    "\t'simple mean' : r2[:,5],\n",
    "\t'min energy' : r2[:,6]\n",
    "}\n",
    "\n",
    "if save: dump(results, 'results_'+experiment_name+'_rs'+str(rs)+'.joblib')\n",
    "\n",
    "for k in results.keys():\n",
    "\tprint(f'{k}: {results[k]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run experiments searching for epsilon, C and gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exiting cell as search_svr_hps is set to False\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "WARNING: THIS CELL SENDS PROBLEMS TO D-WAVE MULTIPLE TIMES\n",
    "REMEMBRER D-WAVE AVALIABLE TIME IS LIMITED\n",
    "'''\n",
    "if not search_svr_hps: #ONLY RUNS if user wants to search for: epsilon, C and gamma\n",
    "\tnb_utils.exit_cell('Exiting cell as search_svr_hps is set to False')\n",
    "\t\n",
    "# load data\n",
    "df_info = nb_utils.get_df_info('mlpf')\n",
    "df = pd.read_csv(df_info['df_path'])\n",
    "df = df.drop(df[df.loss_99 == df.loss_99.max()].index)\n",
    "\n",
    "# Select features\n",
    "curve = nb_utils.get_curve(df_info=df_info, known_curve=0.25, df=df)\n",
    "X = curve[:,[i for i in range(0,curve.shape[1],2)]]\n",
    "\n",
    "# Prediction target\n",
    "y = nb_utils.get_target(df_info,df)\n",
    "\n",
    "# Scale data\n",
    "x_scaler = QuantileTransformer(n_quantiles=50,random_state=0)\n",
    "X = x_scaler.fit_transform(X)\n",
    "y_scaler =  QuantileTransformer(n_quantiles=50,random_state=0)\n",
    "y = y_scaler.fit_transform(y.reshape(-1, 1)).ravel()\n",
    "\n",
    "rs = randint(0, 2**30)\n",
    "num_runs = 0\n",
    "r2 = np.zeros((num_runs, 7))\n",
    "for i in range(num_runs):\n",
    "\t# train test split\n",
    "\tX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=200, random_state=rs+i)\n",
    "\n",
    "\t# Optimiza SVR hps using classical SVR\n",
    "\tbest, C_best, epsilon_best, gamma_best = -100, None, None, None\n",
    "\tfor j in range(5000):\n",
    "\t\t#C = loguniform.rvs(1e0,1e3)\n",
    "\t\tC = loguniform.rvs(5.0,1e3) # after experiment this range seems probably better for qsvr \n",
    "\t\t#gamma = loguniform.rvs(1e-5,10)\n",
    "\t\tgamma = loguniform.rvs(0.01,10) # after experiment this range seems probably better for qsvr \n",
    "\t\t#epsilon = loguniform.rvs(1e-3,1e0)\n",
    "\t\tepsilon = loguniform.rvs(1e-3,0.4) # after experiment this range seems probably better for qsvr \n",
    "\t\tmodel = SVR(C=C,epsilon=epsilon,gamma=gamma)\n",
    "\t\tcvs, __ = nb_utils.small_train_r2_cv(model, X=X_train, y=y_train, train_size= 20, reps=5, test_size=0.74,rs=rs+j)\n",
    "\t\tcvs = cvs.mean()\n",
    "\t\tif best < cvs:\n",
    "\t\t\tbest = cvs\n",
    "\t\tC_best, epsilon_best, gamma_best = C, epsilon, gamma\n",
    "\t\n",
    "\tB = 0.5\n",
    "\tK = 3\n",
    "\tk0 = 0.005\n",
    "\texponents_array = np.array(list(range(K)))\n",
    "\texponents_array = exponents_array-k0\n",
    "\tC_min = sum(np.power(B, exponents_array))\n",
    "\t\n",
    "\tif (C_best < C_min): \n",
    "\t\tC_best = C_min\n",
    "\t\t\t\n",
    "\tprint(pd.DataFrame({'CV mean R^2': best, 'C': C_best, 'epsilon': epsilon_best, 'gamma': gamma_best}, index=['Best hyperparameters']))\n",
    "\n",
    "\tX_train, _, y_train, _ = train_test_split(X, y, train_size=20, random_state=rs+i)\n",
    "\n",
    "\t# QSVR code\n",
    "\tqsvr_model = QSVR.QSVR() # instantiate\n",
    "\t#RUN ON D-WAVE\n",
    "\t#set sampler\n",
    "\tsampler = LazyFixedEmbeddingComposite(DWaveSampler(region='na-west-1', solver='Advantage_system6.1'))\n",
    "\tqsvr_model.fit(X_train, y_train,\n",
    "\t\t\tK = K, B = B,\n",
    "\t\t\tepsilon = epsilon_best, k0 = k0,\n",
    "\t\t\txi=0.01, n_samples = 20, num_reads = 1000,\n",
    "\t\t\trandom_seed=rs+i,\n",
    "\t\t\tn_samples_for_gamma_and_C_optimizations=0,\n",
    "\t\t\tgamma=gamma_best, C=C_best,\n",
    "\t\t\tuse_custom_chainstrength=True,\n",
    "\t\t\tchain_mult=8,\n",
    "\t\t\tsampler=sampler)\n",
    "\t\n",
    "\tif save: nb_utils.save_qsvr(qsvr_model, 'qsvr_attrs_'+experiment_name+'_rs'+str(rs)+'_i'+str(i)) # save QSVR for further predictions\n",
    "\t# evaluate QSVR\n",
    "\ty_pred = qsvr_model.predict(X_test)\n",
    "\tfor j in range(7):\n",
    "\t\tr2[i,j] = r2_score(y_pred[j],y_test)\n",
    "\tprint(f'Finished run {i} with r2 = {r2[i,:]}')\n",
    "results = {\n",
    "\t'scores norm' : r2[:,0],\n",
    "\t'scores softmax' : r2[:,1],\n",
    "\t'scores lc norm' : r2[:,2],\n",
    "\t'scores lc softmax' : r2[:,3],\n",
    "\t'best set of alphas' : r2[:,4],\n",
    "\t'simple mean' : r2[:,5]\n",
    "}\n",
    "\n",
    "if save: dump(results, 'results_'+experiment_name+'_rs'+str(rs)+'.joblib')\n",
    "\n",
    "for k in results.keys():\n",
    "\tprint(f'{k}: {results[k]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analize experiment results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment following line(s) if you want to analize results of a saved experiment\n",
    "#results = load('../results/good_qsvr/chain_str_10/results_eric_params_chain_10_hp_search_rs965737426.joblib')\n",
    "#sufix = '_eric_params_chain_10_hp_search_rs965737426'\n",
    "#folder_path = '../results/good_qsvr/chain_str_10/'\n",
    "#rs = 965737426"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary R^2 Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>scores norm</td>\n",
       "      <td>0.641861</td>\n",
       "      <td>0.948413</td>\n",
       "      <td>0.865821</td>\n",
       "      <td>0.894811</td>\n",
       "      <td>0.086095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>scores softmax</td>\n",
       "      <td>0.760638</td>\n",
       "      <td>0.946151</td>\n",
       "      <td>0.878661</td>\n",
       "      <td>0.893369</td>\n",
       "      <td>0.054855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>scores lc norm</td>\n",
       "      <td>0.640308</td>\n",
       "      <td>0.948421</td>\n",
       "      <td>0.865287</td>\n",
       "      <td>0.894510</td>\n",
       "      <td>0.086750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>scores lc softmax</td>\n",
       "      <td>0.742472</td>\n",
       "      <td>0.948311</td>\n",
       "      <td>0.880937</td>\n",
       "      <td>0.896780</td>\n",
       "      <td>0.056134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>best set of alphas</td>\n",
       "      <td>0.761256</td>\n",
       "      <td>0.946151</td>\n",
       "      <td>0.876103</td>\n",
       "      <td>0.892239</td>\n",
       "      <td>0.056913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>simple mean</td>\n",
       "      <td>-0.701135</td>\n",
       "      <td>0.897623</td>\n",
       "      <td>0.658647</td>\n",
       "      <td>0.866834</td>\n",
       "      <td>0.470536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>min energy</td>\n",
       "      <td>0.735379</td>\n",
       "      <td>0.915576</td>\n",
       "      <td>0.845504</td>\n",
       "      <td>0.852980</td>\n",
       "      <td>0.057063</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               method       min       max      mean    median       std\n",
       "0         scores norm  0.641861  0.948413  0.865821  0.894811  0.086095\n",
       "1      scores softmax  0.760638  0.946151  0.878661  0.893369  0.054855\n",
       "2      scores lc norm  0.640308  0.948421  0.865287  0.894510  0.086750\n",
       "3   scores lc softmax  0.742472  0.948311  0.880937  0.896780  0.056134\n",
       "4  best set of alphas  0.761256  0.946151  0.876103  0.892239  0.056913\n",
       "5         simple mean -0.701135  0.897623  0.658647  0.866834  0.470536\n",
       "6          min energy  0.735379  0.915576  0.845504  0.852980  0.057063"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary = pd.DataFrame(columns = ['method', 'min', 'max', 'mean', 'median', 'std'])\n",
    "for k in results.keys():\n",
    "    summary.loc[len(summary.index)] =[k,\n",
    "        results[k].min(),\n",
    "        results[k].max(),\n",
    "        results[k].mean(),\n",
    "        np.median(results[k]),\n",
    "        results[k].std()]\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "barWidth = 0.25\n",
    "\n",
    "fig = plt.subplots(figsize =(12, 8))\n",
    "plt.grid()\n",
    "plt.gca().set_axisbelow(True)\n",
    " \n",
    "# set height of bar\n",
    "#MIN = [val.min() for val in results.values()]\n",
    "MEAN = [val.mean() for val in results.values()]\n",
    "MEDIAN = [np.median(val) for val in results.values()]\n",
    "MAX = [val.max() for val in results.values()]\n",
    " \n",
    "# Set position of bar on X axis\n",
    "br1 = np.arange(len(results))\n",
    "br2 = [x + barWidth for x in br1]\n",
    "br3 = [x + barWidth for x in br2]\n",
    " \n",
    "# Make the plot\n",
    "plt.bar(br1, MEAN, width = barWidth, label ='Mean')\n",
    "plt.bar(br2, MEDIAN, width = barWidth, label ='Median')\n",
    "plt.bar(br3, MAX, width = barWidth, label ='Max')\n",
    "\n",
    "# Adding Xticks\n",
    "plt.ylabel('$R^2$', fontweight ='bold', fontsize = 15)\n",
    "plt.xticks([r + barWidth for r in range(len(results.keys()))], list(results.keys()))\n",
    "plt.yticks(np.arange(0, 1.1, 0.1))\n",
    "\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate a data frame with the SVR hps and the R^2 values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epsilon</th>\n",
       "      <th>C</th>\n",
       "      <th>gamma</th>\n",
       "      <th>scores norm</th>\n",
       "      <th>scores softmax</th>\n",
       "      <th>scores lc norm</th>\n",
       "      <th>scores lc softmax</th>\n",
       "      <th>best set of alphas</th>\n",
       "      <th>simple mean</th>\n",
       "      <th>min energy</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.02</td>\n",
       "      <td>67.61</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.918006</td>\n",
       "      <td>0.915989</td>\n",
       "      <td>0.918008</td>\n",
       "      <td>0.917845</td>\n",
       "      <td>0.915989</td>\n",
       "      <td>0.829528</td>\n",
       "      <td>0.839459</td>\n",
       "      <td>0.893546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02</td>\n",
       "      <td>67.61</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.908366</td>\n",
       "      <td>0.900612</td>\n",
       "      <td>0.908368</td>\n",
       "      <td>0.900904</td>\n",
       "      <td>0.900612</td>\n",
       "      <td>0.900653</td>\n",
       "      <td>0.896475</td>\n",
       "      <td>0.902284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02</td>\n",
       "      <td>67.61</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.898760</td>\n",
       "      <td>0.896701</td>\n",
       "      <td>0.898709</td>\n",
       "      <td>0.896369</td>\n",
       "      <td>0.896701</td>\n",
       "      <td>0.843065</td>\n",
       "      <td>0.896701</td>\n",
       "      <td>0.889572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.02</td>\n",
       "      <td>67.61</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.928713</td>\n",
       "      <td>0.929741</td>\n",
       "      <td>0.928320</td>\n",
       "      <td>0.933365</td>\n",
       "      <td>0.926246</td>\n",
       "      <td>0.765396</td>\n",
       "      <td>0.930929</td>\n",
       "      <td>0.906101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.02</td>\n",
       "      <td>67.61</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.900754</td>\n",
       "      <td>0.872377</td>\n",
       "      <td>0.900723</td>\n",
       "      <td>0.872460</td>\n",
       "      <td>0.872377</td>\n",
       "      <td>0.903456</td>\n",
       "      <td>0.855438</td>\n",
       "      <td>0.882512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.02</td>\n",
       "      <td>67.61</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.866953</td>\n",
       "      <td>0.816396</td>\n",
       "      <td>0.866395</td>\n",
       "      <td>0.869525</td>\n",
       "      <td>0.800899</td>\n",
       "      <td>0.851678</td>\n",
       "      <td>0.859950</td>\n",
       "      <td>0.847399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.02</td>\n",
       "      <td>67.61</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.563372</td>\n",
       "      <td>0.721390</td>\n",
       "      <td>0.561123</td>\n",
       "      <td>0.705410</td>\n",
       "      <td>0.721576</td>\n",
       "      <td>0.313343</td>\n",
       "      <td>0.721576</td>\n",
       "      <td>0.615399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.02</td>\n",
       "      <td>67.61</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.912116</td>\n",
       "      <td>0.901188</td>\n",
       "      <td>0.912134</td>\n",
       "      <td>0.910170</td>\n",
       "      <td>0.899850</td>\n",
       "      <td>0.901138</td>\n",
       "      <td>0.855820</td>\n",
       "      <td>0.898917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.02</td>\n",
       "      <td>67.61</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.786106</td>\n",
       "      <td>0.887513</td>\n",
       "      <td>0.783153</td>\n",
       "      <td>0.856561</td>\n",
       "      <td>0.886101</td>\n",
       "      <td>-0.793957</td>\n",
       "      <td>0.706098</td>\n",
       "      <td>0.587368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.02</td>\n",
       "      <td>67.61</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.936158</td>\n",
       "      <td>0.940654</td>\n",
       "      <td>0.936253</td>\n",
       "      <td>0.941027</td>\n",
       "      <td>0.940654</td>\n",
       "      <td>0.887655</td>\n",
       "      <td>0.846170</td>\n",
       "      <td>0.918367</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epsilon      C  gamma  scores norm  scores softmax  scores lc norm  \\\n",
       "0     0.02  67.61    0.1     0.918006        0.915989        0.918008   \n",
       "1     0.02  67.61    0.1     0.908366        0.900612        0.908368   \n",
       "2     0.02  67.61    0.1     0.898760        0.896701        0.898709   \n",
       "3     0.02  67.61    0.1     0.928713        0.929741        0.928320   \n",
       "4     0.02  67.61    0.1     0.900754        0.872377        0.900723   \n",
       "5     0.02  67.61    0.1     0.866953        0.816396        0.866395   \n",
       "6     0.02  67.61    0.1     0.563372        0.721390        0.561123   \n",
       "7     0.02  67.61    0.1     0.912116        0.901188        0.912134   \n",
       "8     0.02  67.61    0.1     0.786106        0.887513        0.783153   \n",
       "9     0.02  67.61    0.1     0.936158        0.940654        0.936253   \n",
       "\n",
       "   scores lc softmax  best set of alphas  simple mean  min energy      mean  \n",
       "0           0.917845            0.915989     0.829528    0.839459  0.893546  \n",
       "1           0.900904            0.900612     0.900653    0.896475  0.902284  \n",
       "2           0.896369            0.896701     0.843065    0.896701  0.889572  \n",
       "3           0.933365            0.926246     0.765396    0.930929  0.906101  \n",
       "4           0.872460            0.872377     0.903456    0.855438  0.882512  \n",
       "5           0.869525            0.800899     0.851678    0.859950  0.847399  \n",
       "6           0.705410            0.721576     0.313343    0.721576  0.615399  \n",
       "7           0.910170            0.899850     0.901138    0.855820  0.898917  \n",
       "8           0.856561            0.886101    -0.793957    0.706098  0.587368  \n",
       "9           0.941027            0.940654     0.887655    0.846170  0.918367  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "df_info = nb_utils.get_df_info('mlpf')\n",
    "df = pd.read_csv(df_info['df_path'])\n",
    "df = df.drop(df[df.loss_99 == df.loss_99.max()].index)\n",
    "\n",
    "# Select features\n",
    "curve = nb_utils.get_curve(df_info=df_info, known_curve=0.25, df=df)\n",
    "X = curve[:,[i for i in range(0,curve.shape[1],2)]]\n",
    "\n",
    "# Prediction target\n",
    "y = nb_utils.get_target(df_info,df)\n",
    "\n",
    "# Scale data: May Need to load an Scaler if a different one was used for the original experiment\n",
    "x_scaler = QuantileTransformer(n_quantiles=50,random_state=0)\n",
    "X = x_scaler.fit_transform(X)\n",
    "y_scaler =  QuantileTransformer(n_quantiles=50,random_state=0)\n",
    "y = y_scaler.fit_transform(y.reshape(-1, 1)).ravel()\n",
    "\n",
    "info = pd.DataFrame(columns = ['epsilon', 'C', 'gamma', 'scores norm', 'scores softmax', 'scores lc norm', 'scores lc softmax', 'best set of alphas', 'simple mean', 'min energy', 'mean'])\n",
    "for i in range(10):\n",
    "    ld_qsvr_attrs = load(folder_path+\"qsvr_attrs\"+sufix+\"_i\"+str(i)+\".joblib\")\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=200, random_state=rs+i)\n",
    "\n",
    "    epsilon = ld_qsvr_attrs[\"epsilon\"]\n",
    "    gamma = ld_qsvr_attrs[\"best_gamma\"]\n",
    "    C = ld_qsvr_attrs[\"best_C\"]\n",
    "    row = [epsilon, C, gamma]\n",
    "\n",
    "    pred_model = QSVR.QSVR() \n",
    "    \n",
    "    # set the QSVR attributes needed for predictions\n",
    "    for attr in ld_qsvr_attrs.keys():\n",
    "        setattr(pred_model, attr, ld_qsvr_attrs[attr])\n",
    "\n",
    "\n",
    "    # use the QSVR to do a prediction\n",
    "    # loaded scalers may be needed\n",
    "    y_pred = pred_model.predict(X_test)\n",
    "\n",
    "    # make use of the prediction\n",
    "    r2s = []\n",
    "    for i in range(y_pred.shape[0]):\n",
    "        r2s.append(r2_score(y_pred[i],y_test))\n",
    "\n",
    "    row.extend(r2s)\n",
    "    row.append(np.array(r2s).mean())\n",
    "\n",
    "    info.loc[len(info.index)] = row\n",
    "\n",
    "info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Redo an experiment now using simulated annealing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the QUBO Q matrix of size (120, 120)\n",
      "Extracting nodes and couplers from Q\n",
      "The problem has 120 nodes and 7140 couplers\n",
      "Running with 120 nodes and 7140 couplers\n",
      "no field of name chain_break_fraction\n",
      "->trying with: result = rfn.merge_arrays((unique_samples, unique_records[\"energy\"], unique_counts))\n",
      "Creating the QUBO Q matrix of size (120, 120)\n",
      "Extracting nodes and couplers from Q\n",
      "The problem has 120 nodes and 7140 couplers\n",
      "Running with 120 nodes and 7140 couplers\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "df_info = nb_utils.get_df_info('mlpf')\n",
    "df = pd.read_csv(df_info['df_path'])\n",
    "df = df.drop(df[df.loss_99 == df.loss_99.max()].index)\n",
    "\n",
    "# Select features\n",
    "curve = nb_utils.get_curve(df_info=df_info, known_curve=0.25, df=df)\n",
    "X = curve[:,[i for i in range(0,curve.shape[1],2)]]\n",
    "\n",
    "# Prediction target\n",
    "y = nb_utils.get_target(df_info,df)\n",
    "\n",
    "# Scale data: May Need to load an Scaler if a different one was used for the original experiment\n",
    "x_scaler = QuantileTransformer(n_quantiles=50,random_state=0)\n",
    "X = x_scaler.fit_transform(X)\n",
    "y_scaler =  QuantileTransformer(n_quantiles=50,random_state=0)\n",
    "y = y_scaler.fit_transform(y.reshape(-1, 1)).ravel()\n",
    "\n",
    "annealed_info = pd.DataFrame(columns = ['epsilon', 'C', 'gamma', 'scores norm', 'scores softmax', 'scores lc norm', 'scores lc softmax', 'best set of alphas', 'simple mean', 'min energy', 'mean'])\n",
    "for i in range(10):\n",
    "\tload(folder_path+\"qsvr_attrs\"+sufix+\"_i\"+str(i)+\".joblib\")\n",
    "\tX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=200, random_state=rs+i)\n",
    "\tX_train, _, y_train, _ = train_test_split(X, y, train_size=20, random_state=rs+i)\n",
    "\n",
    "\tepsilon = ld_qsvr_attrs[\"epsilon\"]\n",
    "\tgamma = ld_qsvr_attrs[\"best_gamma\"]\n",
    "\tC = ld_qsvr_attrs[\"best_C\"]\n",
    "\trow = [epsilon, C, gamma]\n",
    "\tB = 0.5\n",
    "\tK = 3\n",
    "\tk0 = 0.005\n",
    "\n",
    "\t# QSVR code\n",
    "\tqsvr_model = QSVR.QSVR() # instantiate\n",
    "\t#RUN ON D-WAVE\n",
    "\t#set sampler\n",
    "\tsampler = neal.SimulatedAnnealingSampler()\n",
    "\tqsvr_model.fit(X_train, y_train,\n",
    "\t\t\tK = K, B = B,\n",
    "\t\t\tepsilon = epsilon, k0 = k0,\n",
    "\t\t\txi=0.01, n_samples = 20, num_reads = 1000,\n",
    "\t\t\trandom_seed=rs+i,\n",
    "\t\t\tn_samples_for_gamma_and_C_optimizations=0,\n",
    "\t\t\tgamma=gamma, C=C,\n",
    "\t\t\tuse_custom_chainstrength=True,\n",
    "\t\t\tchain_mult=8,\n",
    "\t\t\tsampler=sampler)\n",
    "\n",
    "\t# use the QSVR to do a prediction\n",
    "\t# loaded scalers may be needed\n",
    "\ty_pred = pred_model.predict(X_test)\n",
    "\n",
    "\t# make use of the prediction\n",
    "\tr2s = []\n",
    "\tfor i in range(y_pred.shape[0]):\n",
    "\t\tr2s.append(r2_score(y_pred[i],y_test))\n",
    "\n",
    "\trow.extend(r2s)\n",
    "\trow.append(np.array(r2s).mean())\n",
    "\n",
    "\tannealed_info.loc[len(annealed_info.index)] = row\n",
    "\n",
    "annealed_info"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('py39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1ac4248432e308955067782465497de26ed69bab2d310610bc1af3ad0fd9ab68"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
