{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import inf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import NuSVR\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from joblib import dump #more efficient than pickle on objects that carry large numpy arrays internally\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bin_size</th>\n",
       "      <th>dropout</th>\n",
       "      <th>lr</th>\n",
       "      <th>n_glayers_id</th>\n",
       "      <th>n_glayers_reg</th>\n",
       "      <th>loss_0</th>\n",
       "      <th>loss_1</th>\n",
       "      <th>loss_2</th>\n",
       "      <th>loss_3</th>\n",
       "      <th>loss_4</th>\n",
       "      <th>...</th>\n",
       "      <th>loss_90</th>\n",
       "      <th>loss_91</th>\n",
       "      <th>loss_92</th>\n",
       "      <th>loss_93</th>\n",
       "      <th>loss_94</th>\n",
       "      <th>loss_95</th>\n",
       "      <th>loss_96</th>\n",
       "      <th>loss_97</th>\n",
       "      <th>loss_98</th>\n",
       "      <th>loss_99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16.0</td>\n",
       "      <td>0.006203</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>533.897949</td>\n",
       "      <td>533.939148</td>\n",
       "      <td>533.939026</td>\n",
       "      <td>533.938904</td>\n",
       "      <td>533.938843</td>\n",
       "      <td>...</td>\n",
       "      <td>533.938782</td>\n",
       "      <td>533.938782</td>\n",
       "      <td>533.938782</td>\n",
       "      <td>533.938782</td>\n",
       "      <td>533.938782</td>\n",
       "      <td>533.938782</td>\n",
       "      <td>533.938782</td>\n",
       "      <td>533.938782</td>\n",
       "      <td>533.938782</td>\n",
       "      <td>533.938782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16.0</td>\n",
       "      <td>0.257000</td>\n",
       "      <td>0.000340</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>492.217072</td>\n",
       "      <td>471.338928</td>\n",
       "      <td>472.664246</td>\n",
       "      <td>473.120575</td>\n",
       "      <td>472.047882</td>\n",
       "      <td>...</td>\n",
       "      <td>474.869324</td>\n",
       "      <td>474.922974</td>\n",
       "      <td>474.983826</td>\n",
       "      <td>474.955231</td>\n",
       "      <td>475.082001</td>\n",
       "      <td>475.255493</td>\n",
       "      <td>492.020630</td>\n",
       "      <td>471.808075</td>\n",
       "      <td>472.234894</td>\n",
       "      <td>472.483948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>64.0</td>\n",
       "      <td>0.302990</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>529.882935</td>\n",
       "      <td>494.913788</td>\n",
       "      <td>492.469879</td>\n",
       "      <td>495.969910</td>\n",
       "      <td>498.249359</td>\n",
       "      <td>...</td>\n",
       "      <td>526.383667</td>\n",
       "      <td>526.397461</td>\n",
       "      <td>526.396484</td>\n",
       "      <td>526.405334</td>\n",
       "      <td>526.412476</td>\n",
       "      <td>526.418274</td>\n",
       "      <td>526.422729</td>\n",
       "      <td>526.416870</td>\n",
       "      <td>526.419739</td>\n",
       "      <td>526.418579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32.0</td>\n",
       "      <td>0.172210</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>543.924561</td>\n",
       "      <td>484.485809</td>\n",
       "      <td>472.445312</td>\n",
       "      <td>467.696869</td>\n",
       "      <td>464.545593</td>\n",
       "      <td>...</td>\n",
       "      <td>448.215912</td>\n",
       "      <td>544.031372</td>\n",
       "      <td>484.386292</td>\n",
       "      <td>472.220398</td>\n",
       "      <td>467.484924</td>\n",
       "      <td>464.688690</td>\n",
       "      <td>462.955078</td>\n",
       "      <td>461.424591</td>\n",
       "      <td>460.127716</td>\n",
       "      <td>459.114685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>64.0</td>\n",
       "      <td>0.422810</td>\n",
       "      <td>0.000220</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>507.416473</td>\n",
       "      <td>467.467712</td>\n",
       "      <td>465.895966</td>\n",
       "      <td>465.514557</td>\n",
       "      <td>465.184174</td>\n",
       "      <td>...</td>\n",
       "      <td>467.200775</td>\n",
       "      <td>466.911926</td>\n",
       "      <td>464.984131</td>\n",
       "      <td>464.936554</td>\n",
       "      <td>465.855988</td>\n",
       "      <td>465.208282</td>\n",
       "      <td>465.407593</td>\n",
       "      <td>465.519531</td>\n",
       "      <td>465.818481</td>\n",
       "      <td>466.210205</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 105 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   bin_size   dropout        lr  n_glayers_id  n_glayers_reg      loss_0  \\\n",
       "0      16.0  0.006203  0.000141           4.0            1.0  533.897949   \n",
       "1      16.0  0.257000  0.000340           1.0            2.0  492.217072   \n",
       "2      64.0  0.302990  0.000250           2.0            0.0  529.882935   \n",
       "3      32.0  0.172210  0.000042           3.0            2.0  543.924561   \n",
       "4      64.0  0.422810  0.000220           3.0            1.0  507.416473   \n",
       "\n",
       "       loss_1      loss_2      loss_3      loss_4  ...     loss_90  \\\n",
       "0  533.939148  533.939026  533.938904  533.938843  ...  533.938782   \n",
       "1  471.338928  472.664246  473.120575  472.047882  ...  474.869324   \n",
       "2  494.913788  492.469879  495.969910  498.249359  ...  526.383667   \n",
       "3  484.485809  472.445312  467.696869  464.545593  ...  448.215912   \n",
       "4  467.467712  465.895966  465.514557  465.184174  ...  467.200775   \n",
       "\n",
       "      loss_91     loss_92     loss_93     loss_94     loss_95     loss_96  \\\n",
       "0  533.938782  533.938782  533.938782  533.938782  533.938782  533.938782   \n",
       "1  474.922974  474.983826  474.955231  475.082001  475.255493  492.020630   \n",
       "2  526.397461  526.396484  526.405334  526.412476  526.418274  526.422729   \n",
       "3  544.031372  484.386292  472.220398  467.484924  464.688690  462.955078   \n",
       "4  466.911926  464.984131  464.936554  465.855988  465.208282  465.407593   \n",
       "\n",
       "      loss_97     loss_98     loss_99  \n",
       "0  533.938782  533.938782  533.938782  \n",
       "1  471.808075  472.234894  472.483948  \n",
       "2  526.416870  526.419739  526.418579  \n",
       "3  461.424591  460.127716  459.114685  \n",
       "4  465.519531  465.818481  466.210205  \n",
       "\n",
       "[5 rows x 105 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/mnist/all_4hp_rusty.csv')\n",
    "df = pd.read_csv('../data/mlpf/delphes_trainings_processed.csv')\n",
    "df = df.iloc[:300]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "known_curve = 0.25\n",
    "min_hp_idx = 0\n",
    "min_curve_idx = 6\n",
    "max_hp_idx = 5 #when using 6hp search space\n",
    "#max_hp_idx = 3  #when using 4hp search space\n",
    "\n",
    "hps = df[df.columns[min_hp_idx:max_hp_idx+1]].to_numpy()\n",
    "\n",
    "curve = df[df.columns[min_curve_idx:min_curve_idx+int(num_epochs*known_curve)]].to_numpy()\n",
    "target = df[df.columns[min_curve_idx+num_epochs-2]].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate finite diferences of 1st and 2nd order\n",
    "def finite_difs(curve):\n",
    "    difs1 = []\n",
    "    for i in range(curve.shape[0]):\n",
    "        difs1.append([])\n",
    "        for j in range(1,curve.shape[1]):\n",
    "            difs1[i].append(curve[i][j]-curve[i][j-1])\n",
    "    difs2 = []\n",
    "    for i in range(curve.shape[0]):\n",
    "        difs2.append([])\n",
    "        for j in range(1,len(difs1[0])):\n",
    "            difs2[i].append(difs1[i][j]-difs1[i][j-1])\n",
    "    difs1 = np.array(difs1)\n",
    "    difs2 = np.array(difs2)\n",
    "    return difs1, difs2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "difs1, difs2 = finite_difs(curve)\n",
    "X = np.append(np.append(np.append(hps,curve,1),difs1,1),difs2,1)\n",
    "y = target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['y_scaler.joblib']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scale\n",
    "x_scaler = MinMaxScaler()\n",
    "y_scaler = MinMaxScaler()\n",
    "X = x_scaler.fit_transform(X)\n",
    "y = y_scaler.fit_transform(y.reshape(-1, 1))\n",
    "#save the scalers so that they can be used when using the SVR in another program\n",
    "dump(x_scaler,\"x_scaler.joblib\") \n",
    "dump(y_scaler,\"y_scaler.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17, 78) (5, 78)\n"
     ]
    }
   ],
   "source": [
    "#split in train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "print(str(X_train.shape)+\" \"+str(X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NuSVR()"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#instatiate and train predictor\n",
    "model = NuSVR()\n",
    "model.fit(X_train,y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save model\n",
    "filename = \"modelo.joblib\"\n",
    "dump(model, \"modelo.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.007594152785532956"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#MSE\n",
    "y_pred = model.predict(X_test)\n",
    "mean_squared_error(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9424735651718144"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#R^2\n",
    "model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.98815634, 0.71272339, 0.93303573, 0.24733088, 0.86056278]),\n",
       " 0.7483618249489711,\n",
       " 0.2670194845487989)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvs = cross_val_score(model, X_train, y_train.ravel(), cv = 5, scoring='r2')\n",
    "cvs, cvs.mean(), cvs.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 887,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7663090107089143, 7.3135497213543115, 0.8924509605431109, 'scale')"
      ]
     },
     "execution_count": 887,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#try to optimize regressor hps\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "best, C_best, Nu_best, gamma_best = -inf, -inf, -inf, -inf\n",
    "for _ in range(1000):\n",
    "    C = np.exp(np.random.uniform(np.log(1e-3),np.log(10.0)))\n",
    "    Nu = np.random.uniform(0,1)\n",
    "    gamma = \"scale\"\n",
    "    model = NuSVR(C=C,nu=Nu,gamma=gamma)\n",
    "    cvs = cross_val_score(model, X_train, y_train.ravel(), cv = 5, scoring='r2').mean()\n",
    "    if best < cvs:\n",
    "        best = cvs\n",
    "        C_best, Nu_best, gamma_best = C, Nu, gamma\n",
    "best, C_best, Nu_best, gamma_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 888,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7663090107089143"
      ]
     },
     "execution_count": 888,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NuSVR(C=C_best,nu=Nu_best,gamma=gamma_best)\n",
    "model.fit(X_train,y_train.ravel())\n",
    "\n",
    "cvs = cross_val_score(model, X_train, y_train.ravel(), cv = 5, scoring='r2').mean()\n",
    "cvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 889,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0005593760485826635, 0.9531359618257825)"
      ]
     },
     "execution_count": 889,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model.fit(X_train,y_train.ravel())\n",
    "y_pred = model.predict(X_test)\n",
    "mean_squared_error(y_test,y_pred), model.score(X_test,y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('py39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1ac4248432e308955067782465497de26ed69bab2d310610bc1af3ad0fd9ab68"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
